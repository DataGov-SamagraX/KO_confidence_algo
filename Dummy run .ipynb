{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e4c093d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3a0b473",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dotenv_path = Path('.env')\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "\n",
    "#%%  Declaring all the variables\n",
    "\n",
    "## locations where the files with confidence scores need to be saved\n",
    "save_location =  os.getenv('save_location')\n",
    "\n",
    "## csv file with the SQL code repo\n",
    "sql_repo_csv_location =  os.getenv('save_location')\n",
    "\n",
    "## setting the maximum confidence a source can have: \n",
    "maximum_confidence_value = float(os.getenv('maximum_confidence_value'))\n",
    "\n",
    "## setting  the maximum number of iterations in the algo: \n",
    "maximum_number_of_iterations =  float(os.getenv('maximum_number_of_iterations'))\n",
    "\n",
    "## setting the minimum differnce in the trustworthiness scores to be reached to end the algo\n",
    "minimum_absolute_difference =  float(os.getenv('minimum_absolute_difference'))\n",
    "\n",
    "# setting the variables for connecting to the DB:\n",
    "## hostname \n",
    "host = os.getenv('host')\n",
    "\n",
    "##username\n",
    "user = os.getenv('user')\n",
    "\n",
    "##password\n",
    "password=os.getenv('password')\n",
    "\n",
    "##DB name\n",
    "database= os.getenv('database')\n",
    "\n",
    "#%%\n",
    "\n",
    "## connecting to the DB\n",
    "#mydb = mysql.connector.connect(host = host, user = user , password= password , database= database )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1def8b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carry_out_iterations( data,list_of_cols,t_w,id_colname,gamma): \n",
    "    \n",
    "    \"\"\"\n",
    "    Arguments: \n",
    "        data : the table serving as input for the confidence algo \n",
    "        list_of_cols:  list of column names that serve as unique sources for the data points \n",
    "        t_w:  array of initial confidence values (source trustworthiness) for each source. Usually set to 0.5 for each source\n",
    "        id_colname: Column name with unique id value for each row\n",
    "        \n",
    "    Returned values: \n",
    "    t_w_df : table with the changing source trustworthiness with each iteration\n",
    "    train_data_confidence : Final table with the final confidence values for each data point for each source\n",
    "    \n",
    "    \"\"\"\n",
    "        \n",
    "    \n",
    "    max_t_w_value =  0.975\n",
    "    train_data =  data[list_of_cols].copy()\n",
    "    \n",
    "    train_data = train_data.loc[np.sum(~train_data.isna(),axis = 1) > 1,:]\n",
    "    ## creating empty data frame with same structure as traindata to copy confidence scores \n",
    "    \n",
    "    train_data_confidence =  train_data.copy()\n",
    "    train_data_confidence.loc[:,:]= 0\n",
    "\n",
    "    ## calculating (1-t(w)). Carrying out calculation required for the equation\n",
    "    t_w_inv =  1- t_w\n",
    "    tau_w =  -np.log(t_w_inv)\n",
    "\n",
    "    ## creating dataframe that maintains list of confidence values through each iteration\n",
    "    confidence_iterations = pd.DataFrame(columns =train_data.columns.tolist() + ['iteration'])\n",
    "    t_w_df = pd.DataFrame(columns = train_data.columns)\n",
    "\n",
    "    for iteration in range(0,100):\n",
    "\n",
    "        for col_name in list_of_cols:\n",
    "            column_matching_df=  train_data_confidence.copy()\n",
    "            column_matching_df.loc[:,:]= 0\n",
    "            current_source =  train_data[col_name]\n",
    "\n",
    "            other_sources_cols = [x for x in list_of_cols if x != current_source.name]\n",
    "\n",
    "            column_matching_df[col_name] = 1\n",
    "            for col_name_others in other_sources_cols:\n",
    "                column_matching_df[col_name_others] = np.where(train_data[col_name_others]==current_source,1,-1)\n",
    "            column_matching_df[pd.isnull(train_data)]=0\n",
    "\n",
    "            for col_ii in range(0,column_matching_df.shape[1]):\n",
    "                column_matching_df.iloc[:,col_ii] = column_matching_df.iloc[:,col_ii] * tau_w[col_ii]\n",
    "\n",
    "            train_data_confidence[col_name]= np.where(pd.isnull(current_source),np.nan,1/(1 + np.exp( -1 * gamma * ( column_matching_df.sum(axis=1)  ) )))\n",
    "\n",
    "\n",
    "        ## maintaining record of the trusworthiness scores of websites\n",
    "        t_w_prev =  t_w.copy()\n",
    "        t_w_df.loc[iteration]= t_w\n",
    "        t_w = train_data_confidence.mean()\n",
    "        t_w [t_w >= max_t_w_value] = max_t_w_value\n",
    "        t_w_inv =  1- t_w\n",
    "        tau_w =  -np.log(t_w_inv)\n",
    "\n",
    "        ## printing itertion number and the trustworthiness score\n",
    "        print(iteration, np.array(t_w_prev))\n",
    "        if iteration > 5:\n",
    "            if np.nansum(np.abs(t_w.values - t_w_prev.values)) < 0.001:\n",
    "                break\n",
    "    \n",
    "    train_data_confidence[id_colname] =  data[id_colname]\n",
    "    \n",
    "    return(t_w_df,train_data_confidence )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "023e8468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_confidence(data,list_of_cols, column_to_check_confidence,t_w ,id_colname):\n",
    "    \n",
    "    \"\"\"\n",
    "    Arguments: \n",
    "        data : the table serving as input for the confidence algo \n",
    "        list_of_cols:  list of column names that serve as unique sources for the data points \n",
    "        column_to_check_confidence:  column for which final confidence needs to be calcuated \n",
    "        t_w: trustworthiness score for each source (final values from the iterations)\n",
    "        id_colname: colum with unqiue id values for each row\n",
    "        \n",
    "    Returned values: \n",
    "    data  : Table which returns the final confidence scores for the required columns    \n",
    "    \"\"\"\n",
    "        \n",
    "    train_data =  data[list_of_cols].copy()\n",
    "    \n",
    "    column_matching_df =  train_data.copy()\n",
    "    column_matching_df.loc[:,:]= 0\n",
    "    \n",
    "    if (np.isnan(t_w[0])):\n",
    "        t_w[0] = t_w[1]\n",
    "    if (np.isnan(t_w[1])):\n",
    "        t_w[1]= t_w[0]\n",
    "    \n",
    "    \n",
    "    ## calculating (1-t(w)). Carrying out calculation required for the equation\n",
    "    t_w_inv =  1- t_w\n",
    "    tau_w =  -np.log(t_w_inv)\n",
    "\n",
    "    current_source =  data[column_to_check_confidence]\n",
    "\n",
    "    other_sources_cols = [x for x in list_of_cols ]\n",
    "\n",
    "    for col_name_others in other_sources_cols:\n",
    "        column_matching_df[col_name_others] = np.where(train_data[col_name_others]==current_source,1,-1)\n",
    "    column_matching_df[pd.isnull(train_data)]=0\n",
    "\n",
    "    for col_ii in range(0,column_matching_df.shape[1]):\n",
    "        column_matching_df.iloc[:,col_ii] = column_matching_df.iloc[:,col_ii] * tau_w[col_ii]\n",
    "\n",
    "    final_conf_scores= np.where(pd.isnull(current_source),np.nan,1/(1 + np.exp( -1 * gamma * ( column_matching_df.sum(axis=1)  ) )))\n",
    "       \n",
    "\n",
    "    data['final_confidence'] = final_conf_scores\n",
    "\n",
    "    return(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df460dc4",
   "metadata": {},
   "source": [
    "## Reading SQL code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "466f5d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes_df = pd.read_csv(\"sql_code_repo.csv\")\n",
    "codes_df_run = codes_df.loc[codes_df.Multiple_confidence_columns == 1,: ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3404e3a",
   "metadata": {},
   "source": [
    "## Reading sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a603df64",
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "df = pd.read_csv('sample_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71b5b368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.5 0.5 0.5 0.5]\n",
      "1 [0.76914488 0.72480818 0.68164488 0.74414488]\n",
      "2 [0.84991547 0.76496293 0.6895011  0.80882528]\n",
      "3 [0.87760345 0.76143778 0.67667659 0.82803577]\n",
      "4 [0.89071796 0.75569627 0.66999482 0.83585512]\n",
      "5 [0.89741102 0.75230465 0.6670872  0.8388701 ]\n",
      "6 [0.90089923 0.75059064 0.66580865 0.83987167]\n",
      "7 [0.90274472 0.74974834 0.66522531 0.84013584]\n",
      "8 [0.9037324  0.74932927 0.6649483  0.8401687 ]\n"
     ]
    }
   ],
   "source": [
    "list_of_cols = np.array(['Source_A', 'Source_B', 'Source_C', 'Source_D'])\n",
    "#table_name_str  = codes_df.loc[table_no,'Field Name']\n",
    "#df.to_csv( 'data' + table_name_str+str(table_no)+'.csv', encoding = \"utf-8\")\n",
    "\n",
    "df['id'] = df.index\n",
    "#df['Krushak_Odisha'] = df.field.combine_first(df.self)\n",
    "no_cols =  len(list_of_cols)\n",
    "t_w = np.repeat(0.5,no_cols)\n",
    "id_colname = 'id'\n",
    "gamma = 1\n",
    "t_w_df,train_data_confidence = carry_out_iterations( df,list_of_cols,t_w,id_colname, gamma)\n",
    "\n",
    "#column_to_check_confidence = 'Krushak_Odisha'\n",
    "\n",
    "#data_copy = get_final_confidence(df, list_of_cols, column_to_check_confidence,t_w ,id_colname)\n",
    "\n",
    "#conf_table = data_copy[['Krushak_Odisha','int_krushk_id','final_confidence']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
